{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on IMDB dataset for Sentiment Analysis - Traditional ML models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "IMDB dataset having **50K movie reviews for natural language processing** or Text analytics.\n",
    "This is a dataset for **binary sentiment classification** containing 50K movie reviews, **25K from each class**.\n",
    "\n",
    "It contains two columns - \n",
    "* **review** (text)\n",
    "* **sentiment** (positive or negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/preprocesseddata/pre_train.txt\n",
      "/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data['review']\n",
    "data_Y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING\n",
    "\n",
    "The `process_text` function standardizes and cleans text data for natural language processing tasks. It performs the following steps:\n",
    "\n",
    "- **Contraction Expansion:** Expands common English contractions (e.g., \"isn't\" to \"is not\").\n",
    "- **Special Character Removal:** Cleans special characters, emojis, and undesired unicode symbols.\n",
    "- **Word Separation:** Splits up concatenated words and normalizes known compound tokens.\n",
    "- **Lowercasing:** Converts all text to lowercase for consistency.\n",
    "- **Noise Removal:** Removes hyperlinks, specific prefixes (like 'rt@username'), and HTML breaks.\n",
    "- **Punctuation Removal:** Eliminates punctuation and special symbols.\n",
    "- **Stopword Removal:** Removes English stopwords (excluding \"not\") and words shorter than 3 characters.\n",
    "- **Stemming:** Reduces words to their root form using the Porter Stemmer.\n",
    "\n",
    "The output is a cleaned, lowercased, and stemmed string suitable for further NLP tasks such as tokenization or feature extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(line):\n",
    "    \n",
    "    #remove short\n",
    "    line=re.sub(\"isn't\",'is not',line)\n",
    "    line=re.sub(\"he's\",'he is',line)\n",
    "    line=re.sub(\"wasn't\",'was not',line)\n",
    "    line=re.sub(\"there's\",'there is',line)\n",
    "    line=re.sub(\"couldn't\",'could not',line)\n",
    "    line=re.sub(\"won't\",'will not',line)\n",
    "    line=re.sub(\"they're\",'they are',line)\n",
    "    line=re.sub(\"she's\",'she is',line)\n",
    "    line=re.sub(\"There's\",'there is',line)\n",
    "    line=re.sub(\"wouldn't\",'would not',line)\n",
    "    line=re.sub(\"haven't\",'have not',line)\n",
    "    line=re.sub(\"That's\",'That is',line)\n",
    "    line=re.sub(\"you've\",'you have',line)\n",
    "    line=re.sub(\"He's\",'He is',line)\n",
    "    line=re.sub(\"what's\",'what is',line)\n",
    "    line=re.sub(\"weren't\",'were not',line)\n",
    "    line=re.sub(\"we're\",'we are',line)\n",
    "    line=re.sub(\"hasn't\",'has not',line)\n",
    "    line=re.sub(\"you'd\",'you would',line)\n",
    "    line=re.sub(\"shouldn't\",'should not',line)\n",
    "    line=re.sub(\"let's\",'let us',line)\n",
    "    line=re.sub(\"they've\",'they have',line)\n",
    "    line=re.sub(\"You'll\",'You will',line)\n",
    "    line=re.sub(\"i'm\",'i am',line)\n",
    "    line=re.sub(\"we've\",'we have',line)\n",
    "    line=re.sub(\"it's\",'it is',line)\n",
    "    line=re.sub(\"don't\",'do not',line)\n",
    "    line=re.sub(\"that´s\",'that is',line)\n",
    "    line=re.sub(\"I´m\",'I am',line)\n",
    "    line=re.sub(\"it’s\",'it is',line)\n",
    "    line=re.sub(\"she´s\",'she is',line)\n",
    "    line=re.sub(\"he’s'\",'he is',line)\n",
    "    line=re.sub('I’m','I am',line)\n",
    "    line=re.sub('I’d','I did',line)\n",
    "    line=re.sub(\"he’s'\",'he is',line)\n",
    "    line=re.sub('there’s','there is',line)\n",
    "    line = re.sub(r'\\'ll', ' will',line)\n",
    "    \n",
    "    \n",
    "    #special characters and emojis\n",
    "    line=re.sub('\\x91the','the',line)\n",
    "    line=re.sub('\\x97','',line)\n",
    "    line=re.sub('\\x84the','the',line)\n",
    "    line=re.sub('\\uf0b7','',line)\n",
    "    line=re.sub('¡¨','',line)\n",
    "    line=re.sub('\\x95','',line)\n",
    "    line=re.sub('\\x8ei\\x9eek','',line)\n",
    "    line=re.sub('\\xad','',line)\n",
    "    line=re.sub('\\x84bubble','bubble',line)\n",
    "    \n",
    "    # remove concated words\n",
    "    line=re.sub('trivialBoring','trivial Boring',line)\n",
    "    line=re.sub('Justforkix','Just for kix',line)\n",
    "    line=re.sub('Nightbeast','Night beast',line)\n",
    "    line=re.sub('DEATHTRAP','Death Trap',line)\n",
    "    line=re.sub('CitizenX','Citizen X',line)\n",
    "    line=re.sub('10Rated','10 Rated',line)\n",
    "    line=re.sub('_The','_ The',line)\n",
    "    line=re.sub('1Sound','1 Sound',line)\n",
    "    line=re.sub('blahblahblahblahblahblahblahblahblahblahblahblahblahblahblahblahblahblah','blah blah',line)\n",
    "    line=re.sub('ResidentHazard','Resident Hazard',line)\n",
    "    line=re.sub('iameracing','i am racing',line)\n",
    "    line=re.sub('BLACKSNAKE','Black Snake',line)\n",
    "    line=re.sub('DEATHSTALKER','Death Stalker',line)\n",
    "    line=re.sub('_is_','is',line)\n",
    "    line=re.sub('10Fans','10 Fans',line)\n",
    "    line=re.sub('Yellowcoat','Yellow coat',line)\n",
    "    line=re.sub('Spiderbabe','Spider babe',line)\n",
    "    line=re.sub('Frightworld','Fright world',line)\n",
    "    \n",
    "    line = line.lower()\n",
    "    line = re.sub(r'^nrt@[a-z]+[\\s]*', '', line)\n",
    "    line = re.sub(r'^rt@[a-z]+[\\s]*', '', line)\n",
    "    line = re.sub(r'<br />', ' ', line)\n",
    "    \n",
    "    # remove hyperlinks\n",
    "    line = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', line)\n",
    "    \n",
    "    # remove punctuation\n",
    "    line = re.sub(r'[.,!\"#$%&\\'()*+-]', ' ', line)\n",
    "    line = re.sub(r'[/:;<=>?@\\[\\]^_`{|}~\\\\]', ' ', line)\n",
    "    #remove and numbers\n",
    "    #line = re.sub(r'[0-9+]+','',line)\n",
    "    line = re.sub(r\"\\s+\", r\" \", line).strip()\n",
    "    #stopwords and stemming\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    stopwords_english.remove('not')\n",
    "    stemmer = PorterStemmer()\n",
    "    text = \"\"\n",
    "    \n",
    "    for word in line.split():\n",
    "        if word not in stopwords_english and len(word)>2:\n",
    "            stem_word = stemmer.stem(word)\n",
    "            text+=\" \"+stem_word\n",
    "            #text+=\" \" +word\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk not stop'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_text(\"hi.. I am here for a walk. I !won't stop by\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = []\n",
    "\n",
    "for t in data_X:\n",
    "    train.append(process_text(t).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#define path to new file\n",
    "outdirname= '/kaggle/working'\n",
    "datafile = os.path.join(outdirname,\"train.txt\")\n",
    "delimiter = ','\n",
    "delimiter = str(codecs.decode(delimiter,'unicode_escape'))\n",
    "\n",
    "#write new csv file\n",
    "print(\"\\nwriting newly formatted file...\")\n",
    "with open(datafile,'w',encoding = 'utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile,delimiter=delimiter)\n",
    "    for text in train:\n",
    "        writer.writerow([text])\n",
    "print(\"Done writing to file...\")\n",
    "\n",
    "#visualize some lines\n",
    "datafile = os.path.join(outdirname,\"train.txt\")\n",
    "with open(datafile,'rb') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines[:2]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***READING DATA FROM ALREADY PREPROCESSED FILE...***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_path = '/kaggle/input/preprocesseddata/pre_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing file... please wait.\n"
     ]
    }
   ],
   "source": [
    "# readthe file and split into lines\n",
    "print(\"Reading and processing file... please wait.\")\n",
    "lines = open(pre_data_path, encoding = 'utf-8').read().strip().split('\\n')\n",
    "train = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data in to train and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, valid_X, train_Y, valid_Y = train_test_split(train, data_Y, test_size = 0.2,random_state=0,stratify = data_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization with CountVectorizer\n",
    "\n",
    "The code below demonstrates how to convert preprocessed text data into numerical feature vectors using scikit-learn’s `CountVectorizer`:\n",
    "\n",
    "- **Vectorizer Initialization:** A `CountVectorizer` is created to convert a corpus of text documents into a matrix of token counts (Bag-of-Words model).\n",
    "- **Fitting and Transforming:** The vectorizer learns the vocabulary from the training data (`fit_transform`) and encodes both training and validation sets into sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape :  (40000, 64332)\n",
      "X_train.shape :  (10000, 64332)\n",
      "y_train.shape :  (40000,)\n",
      "y_valid.shape :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(decode_error = 'replace')\n",
    "X_train = vectorizer.fit_transform(train_X)\n",
    "X_valid = vectorizer.transform(valid_X)\n",
    "\n",
    "y_train = train_Y\n",
    "y_valid = valid_Y\n",
    "\n",
    "print(\"X_train.shape : \", X_train.shape)\n",
    "print(\"X_train.shape : \", X_valid.shape)\n",
    "print(\"y_train.shape : \", y_train.shape)\n",
    "print(\"y_valid.shape : \", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier for MULTICLASS Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy Score    :  0.936375\n",
      "Validation accuracy Score :  0.8139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.82      5065\n",
      "    positive       0.81      0.82      0.81      4935\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naiveByes_clf = MultinomialNB(alpha = 0.0000000001)\n",
    "\n",
    "naiveByes_clf.fit(X_train,y_train)\n",
    "\n",
    "NB_prediction = naiveByes_clf.predict(X_valid)\n",
    "NB_accuracy = accuracy_score(y_valid,NB_prediction)\n",
    "print(\"training accuracy Score    : \",naiveByes_clf.score(X_train,y_train))\n",
    "print(\"Validation accuracy Score : \",NB_accuracy )\n",
    "print(classification_report(NB_prediction,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24125    negative\n",
      "25498    positive\n",
      "22286    positive\n",
      "26283    positive\n",
      "9209     positive\n",
      "           ...   \n",
      "34152    negative\n",
      "45174    negative\n",
      "36911    negative\n",
      "36332    negative\n",
      "4844     negative\n",
      "Name: sentiment, Length: 10000, dtype: object\n",
      "['negative' 'positive' 'positive' ... 'negative' 'negative' 'negative']\n"
     ]
    }
   ],
   "source": [
    "print(y_valid)\n",
    "print(NB_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.813900\n",
      "Precision: 0.818034\n",
      "Recall: 0.807400\n",
      "F1 score: 0.812682\n",
      "MCC : 0.627853\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_valid,NB_prediction)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_valid,NB_prediction,pos_label='positive')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_valid,NB_prediction,pos_label='positive')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_valid,NB_prediction,pos_label='positive')\n",
    "print('F1 score: %f' % f1)\n",
    "# Matthews Correaltion Coefficient\n",
    "mcc =  matthews_corrcoef(y_valid,NB_prediction)\n",
    "print('MCC : %f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.627800\n",
      "confusion matrix:\n",
      "[[4102  898]\n",
      " [ 963 4037]]\n"
     ]
    }
   ],
   "source": [
    "kappa = cohen_kappa_score(y_valid,NB_prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "matrix = confusion_matrix(y_valid,NB_prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpreting Results:*  \n",
    "- High **Accuracy** indicates generally correct predictions.  \n",
    "- High **Precision** means fewer false positives.  \n",
    "- High **Recall** means fewer false negatives.  \n",
    "- High **F1 Score** suggests both precision and recall are good.  \n",
    "- High **MCC** indicates predictions are reliably correlated with the true labels, even with imbalanced data.\n",
    "\n",
    "- **Cohen’s Kappa**\n",
    "  Measures the agreement between predicted and actual class labels, adjusting for chance agreement.\n",
    "  - *Interpretation:* \n",
    "    - 1: Perfect agreement\n",
    "    - 0: No better than random chance\n",
    "    - Negative: Worse than random\n",
    "  - Higher values mean better model performance beyond random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel = 'rbf', C=1,gamma=0.01)\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "svc_prediction = svc.predict(X_valid)\n",
    "svc_accuracy = accuracy_score(y_valid,svc_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.859700\n",
      "Precision: 0.824463\n",
      "Recall: 0.914000\n",
      "F1 score: 0.866926\n",
      "MCC : 0.723680\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_valid,svc_prediction)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_valid,svc_prediction,pos_label='positive')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_valid,svc_prediction,pos_label='positive')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_valid,svc_prediction,pos_label='positive')\n",
    "print('F1 score: %f' % f1)\n",
    "# Matthews Correaltion Coefficient\n",
    "mcc =  matthews_corrcoef(y_valid,svc_prediction)\n",
    "print('MCC : %f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.719400\n",
      "confusion matrix:\n",
      "[[4027  973]\n",
      " [ 430 4570]]\n"
     ]
    }
   ],
   "source": [
    "kappa = cohen_kappa_score(y_valid,svc_prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "matrix = confusion_matrix(y_valid,svc_prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy Score    :  0.99955\n",
      "Validation accuracy Score :  0.8012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81      5284\n",
      "    positive       0.77      0.82      0.80      4716\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "rf_clf.fit(X_train,y_train)\n",
    "\n",
    "rf_prediction = rf_clf.predict(X_valid)\n",
    "rf_accuracy = accuracy_score(y_valid,rf_prediction)\n",
    "print(\"Training accuracy Score    : \",rf_clf.score(X_train,y_train))\n",
    "print(\"Validation accuracy Score : \",rf_accuracy )\n",
    "print(classification_report(rf_prediction,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.801200\n",
      "Precision: 0.819338\n",
      "Recall: 0.772800\n",
      "F1 score: 0.795389\n",
      "MCC : 0.603374\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_valid,rf_prediction)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_valid,rf_prediction,pos_label='positive')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_valid,rf_prediction,pos_label='positive')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_valid,rf_prediction,pos_label='positive')\n",
    "print('F1 score: %f' % f1)\n",
    "# Matthews Correaltion Coefficient\n",
    "mcc =  matthews_corrcoef(y_valid,rf_prediction)\n",
    "print('MCC : %f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.602400\n",
      "confusion matrix:\n",
      "[[4148  852]\n",
      " [1136 3864]]\n"
     ]
    }
   ],
   "source": [
    "kappa = cohen_kappa_score(y_valid,rf_prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "print(\"confusion matrix:\")\n",
    "matrix = confusion_matrix(y_valid,rf_prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy Score    :  0.7936\n",
      "Validation accuracy Score :  0.7925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.81      0.79      4735\n",
      "    positive       0.82      0.78      0.80      5265\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.79      0.79      0.79     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=0.00005)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "logreg_prediction = logreg.predict(X_valid)\n",
    "logreg_accuracy = accuracy_score(y_valid,logreg_prediction)\n",
    "print(\"Training accuracy Score    : \",logreg.score(X_train,y_train))\n",
    "print(\"Validation accuracy Score : \",logreg_accuracy )\n",
    "print(classification_report(logreg_prediction,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.792500\n",
      "Precision: 0.777778\n",
      "Recall: 0.819000\n",
      "F1 score: 0.797857\n",
      "MCC : 0.585823\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_valid,logreg_prediction)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_valid,logreg_prediction,pos_label='positive')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_valid,logreg_prediction,pos_label='positive')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_valid,logreg_prediction,pos_label='positive')\n",
    "print('F1 score: %f' % f1)\n",
    "# Matthews Correaltion Coefficient\n",
    "mcc =  matthews_corrcoef(y_valid,logreg_prediction)\n",
    "print('MCC : %f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.585000\n",
      "confusion matrix:\n",
      "[[3830 1170]\n",
      " [ 905 4095]]\n"
     ]
    }
   ],
   "source": [
    "kappa = cohen_kappa_score(y_valid,logreg_prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "print(\"confusion matrix:\")\n",
    "matrix = confusion_matrix(y_valid,logreg_prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent-SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy Score    :  0.788325\n",
      "Validation accuracy Score :  0.7817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.77      0.79      5241\n",
      "    positive       0.76      0.80      0.78      4759\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.78      0.78      0.78     10000\n",
      "weighted avg       0.78      0.78      0.78     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(loss = 'log', penalty = 'l2', random_state=0,alpha=0.7)\n",
    "\n",
    "sgd_clf.fit(X_train,y_train)\n",
    "\n",
    "sgd_prediction = sgd_clf.predict(X_valid)\n",
    "sgd_accuracy = accuracy_score(y_valid,sgd_prediction)\n",
    "print(\"Training accuracy Score    : \",sgd_clf.score(X_train,y_train))\n",
    "print(\"Validation accuracy Score : \",sgd_accuracy )\n",
    "print(classification_report(sgd_prediction,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.781700\n",
      "Precision: 0.795966\n",
      "Recall: 0.757600\n",
      "F1 score: 0.776309\n",
      "MCC : 0.564056\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_valid,sgd_prediction)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_valid,sgd_prediction,pos_label='positive')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_valid,sgd_prediction,pos_label='positive')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_valid,sgd_prediction,pos_label='positive')\n",
    "print('F1 score: %f' % f1)\n",
    "# Matthews Correaltion Coefficient\n",
    "mcc =  matthews_corrcoef(y_valid,sgd_prediction)\n",
    "print('MCC : %f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.563400\n",
      "confusion matrix:\n",
      "[[4029  971]\n",
      " [1212 3788]]\n"
     ]
    }
   ],
   "source": [
    "kappa = cohen_kappa_score(y_valid,sgd_prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "print(\"confusion matrix:\")\n",
    "matrix = confusion_matrix(y_valid,sgd_prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG BOOST( BINARY CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:03:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training accuracy Score    :  0.8041\n",
      "Validation accuracy Score :  0.7872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.83      0.77      4300\n",
      "    positive       0.86      0.75      0.80      5700\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.79      0.79      0.79     10000\n",
      "weighted avg       0.80      0.79      0.79     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgboost_clf = xgb.XGBClassifier(eta=0.03)\n",
    "\n",
    "xgboost_clf.fit(X_train, y_train)\n",
    "\n",
    "xgb_prediction = xgboost_clf.predict(X_valid)\n",
    "xgb_accuracy = accuracy_score(y_valid,xgb_prediction)\n",
    "print(\"Training accuracy Score    : \",xgboost_clf.score(X_train,y_train))\n",
    "print(\"Validation accuracy Score : \",xgb_accuracy )\n",
    "print(classification_report(xgb_prediction,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.787200\n",
      "Precision: 0.751930\n",
      "Recall: 0.857200\n",
      "F1 score: 0.801121\n",
      "MCC : 0.580113\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_valid,xgb_prediction)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_valid,xgb_prediction,pos_label='positive')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_valid,xgb_prediction,pos_label='positive')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_valid,xgb_prediction,pos_label='positive')\n",
    "print('F1 score: %f' % f1)\n",
    "# Matthews Correaltion Coefficient\n",
    "mcc =  matthews_corrcoef(y_valid,xgb_prediction)\n",
    "print('MCC : %f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.574400\n",
      "confusion matrix:\n",
      "[[3586 1414]\n",
      " [ 714 4286]]\n"
     ]
    }
   ],
   "source": [
    "kappa = cohen_kappa_score(y_valid,xgb_prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "print(\"confusion matrix:\")\n",
    "matrix = confusion_matrix(y_valid,xgb_prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy Score    :  0.7917\n",
      "Validation accuracy Score :  0.6488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.70      0.60      3790\n",
      "    positive       0.77      0.62      0.69      6210\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.65      0.66      0.64     10000\n",
      "weighted avg       0.68      0.65      0.65     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "knn_prediction = neigh.predict(X_valid)\n",
    "knn_accuracy = accuracy_score(y_valid,knn_prediction)\n",
    "print(\"Training accuracy Score    : \",neigh.score(X_train,y_train))\n",
    "print(\"Validation accuracy Score : \",knn_accuracy )\n",
    "print(classification_report(knn_prediction,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.648800\n",
      "Precision: 0.619807\n",
      "Recall: 0.769800\n",
      "F1 score: 0.686708\n",
      "MCC : 0.306717\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_valid,knn_prediction)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_valid,knn_prediction,pos_label='positive')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_valid,knn_prediction,pos_label='positive')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_valid,knn_prediction,pos_label='positive')\n",
    "print('F1 score: %f' % f1)\n",
    "# Matthews Correaltion Coefficient\n",
    "mcc =  matthews_corrcoef(y_valid,knn_prediction)\n",
    "print('MCC : %f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.297600\n",
      "confusion matrix:\n",
      "[[2639 2361]\n",
      " [1151 3849]]\n"
     ]
    }
   ],
   "source": [
    "kappa = cohen_kappa_score(y_valid,knn_prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "print(\"confusion matrix:\")\n",
    "matrix = confusion_matrix(y_valid,knn_prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.8139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.7872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "      <td>0.7817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.6488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Test accuracy\n",
       "2                 Naive Bayes         0.8139\n",
       "1               Random Forest         0.8012\n",
       "0         Logistic Regression         0.7925\n",
       "5                     XGBoost         0.7872\n",
       "4  Stochastic Gradient Decent         0.7817\n",
       "3                        KNN          0.6488"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': [ 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes','KNN ', \n",
    "              'Stochastic Gradient Decent', 'XGBoost'],\n",
    "    'Test accuracy': [ logreg_accuracy, \n",
    "              rf_accuracy, NB_accuracy,knn_accuracy, \n",
    "              sgd_accuracy, xgb_accuracy]})\n",
    "\n",
    "models.sort_values(by='Test accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
